{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/rafiansari/twitter-sentiment-analysis-on-game-reviews?scriptVersionId=123049240\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown","outputs":[],"execution_count":0},{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score\nimport nltk\nnltk.download('stopwords')\nnltk.download('punkt')\nfrom nltk.corpus import stopwords\nfrom nltk.tokenize import word_tokenize\nfrom nltk.stem.porter import PorterStemmer\n","metadata":{"execution":{"iopub.status.busy":"2023-03-22T18:13:14.481379Z","iopub.execute_input":"2023-03-22T18:13:14.481959Z","iopub.status.idle":"2023-03-22T18:13:16.391172Z","shell.execute_reply.started":"2023-03-22T18:13:14.481907Z","shell.execute_reply":"2023-03-22T18:13:16.389514Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data = pd.read_csv('/kaggle/input/twitter-entity-sentiment-analysis/twitter_training.csv')\nvalid_data = pd.read_csv('/kaggle/input/twitter-entity-sentiment-analysis/twitter_validation.csv')\n\nprint(train_data.head())\nprint(valid_data.head())\n","metadata":{"execution":{"iopub.status.busy":"2023-03-22T18:13:51.491952Z","iopub.execute_input":"2023-03-22T18:13:51.492397Z","iopub.status.idle":"2023-03-22T18:13:51.901092Z","shell.execute_reply.started":"2023-03-22T18:13:51.492355Z","shell.execute_reply":"2023-03-22T18:13:51.897943Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data.columns = ['ID', 'Game', 'Reviews', 'Comments']\nvalid_data.columns = ['ID', 'Game', 'Reviews', 'Comments']","metadata":{"execution":{"iopub.status.busy":"2023-03-22T18:13:57.724315Z","iopub.execute_input":"2023-03-22T18:13:57.724733Z","iopub.status.idle":"2023-03-22T18:13:57.73179Z","shell.execute_reply.started":"2023-03-22T18:13:57.724697Z","shell.execute_reply":"2023-03-22T18:13:57.73085Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Check the column names of the DataFrame\nprint(train_data.columns)\n\n# Check the column names of the DataFrame\nprint(valid_data.columns)","metadata":{"execution":{"iopub.status.busy":"2023-03-22T18:14:00.733886Z","iopub.execute_input":"2023-03-22T18:14:00.734293Z","iopub.status.idle":"2023-03-22T18:14:00.741497Z","shell.execute_reply.started":"2023-03-22T18:14:00.734257Z","shell.execute_reply":"2023-03-22T18:14:00.740233Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"stop_words = set(stopwords.words('english'))\nstemmer = PorterStemmer()\n\nimport numpy as np\n\ndef preprocess(text):\n\n    # Convert null/NaN values to empty strings\n    if isinstance(text, float) and np.isnan(text):\n        text = ''\n    # Convert text to lowercase\n    text = text.lower()\n\n    # Tokenize text\n    words = word_tokenize(text)\n\n    # Remove stop words\n    words = [word for word in words if word not in stop_words]\n\n    # Stem words\n    words = [stemmer.stem(word) for word in words]\n\n    # Join words\n    text = ' '.join(words)\n\n    return text\n\ntrain_data['Comments'] = train_data['Comments'].apply(preprocess)\nvalid_data['Comments'] = valid_data['Comments'].apply(preprocess)\n","metadata":{"execution":{"iopub.status.busy":"2023-03-22T18:14:03.75877Z","iopub.execute_input":"2023-03-22T18:14:03.759776Z","iopub.status.idle":"2023-03-22T18:14:48.117038Z","shell.execute_reply.started":"2023-03-22T18:14:03.759725Z","shell.execute_reply":"2023-03-22T18:14:48.115988Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Feature extraction using TF-IDF vectorization\ntfidf = TfidfVectorizer(max_features=10000)\nX_train = tfidf.fit_transform(train_data['Comments'])\nX_valid = tfidf.transform(valid_data['Comments'])\ny_train = train_data['Reviews']\ny_valid = valid_data['Reviews']\n\n# Train a logistic regression model on the training data\nlr = LogisticRegression(max_iter=1000)\nlr.fit(X_train, y_train)\n\n# Predict the sentiment of the validation data using the trained model\ny_pred = lr.predict(X_valid)\n\n# Calculate the accuracy of the model on the validation data\naccuracy = accuracy_score(y_valid, y_pred)\n\n# Print the accuracy score\nprint(\"Accuracy:\", accuracy)\n\n","metadata":{"execution":{"iopub.status.busy":"2023-03-22T18:14:54.236664Z","iopub.execute_input":"2023-03-22T18:14:54.237087Z","iopub.status.idle":"2023-03-22T18:15:27.528009Z","shell.execute_reply.started":"2023-03-22T18:14:54.237046Z","shell.execute_reply":"2023-03-22T18:15:27.526358Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier\n\n# Create a decision tree classifier\ndt = DecisionTreeClassifier()\n\n# Train the model on the training data\ndt.fit(X_train, y_train)\n\n# Predict the sentiment of the validation data using the trained model\ny_pred = dt.predict(X_valid)\n\n# Calculate the accuracy of the model on the validation data\naccuracy = accuracy_score(y_valid, y_pred)\n\n# Print the accuracy score\nprint(\"Accuracy:\", accuracy)\n","metadata":{"execution":{"iopub.status.busy":"2023-03-22T18:15:34.25321Z","iopub.execute_input":"2023-03-22T18:15:34.253597Z","iopub.status.idle":"2023-03-22T18:15:58.659636Z","shell.execute_reply.started":"2023-03-22T18:15:34.253562Z","shell.execute_reply":"2023-03-22T18:15:58.658391Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\n\n# Create a random forest classifier with 100 trees\nrf = RandomForestClassifier(n_estimators=100)\n\n# Train the model on the training data\nrf.fit(X_train, y_train)\n\n# Predict the sentiment of the validation data using the trained model\ny_pred = rf.predict(X_valid)\n\n# Calculate the accuracy of the model on the validation data\naccuracy = accuracy_score(y_valid, y_pred)\n\n# Print the accuracy score\nprint(\"Accuracy:\", accuracy)\n","metadata":{"execution":{"iopub.status.busy":"2023-03-22T18:16:03.53189Z","iopub.execute_input":"2023-03-22T18:16:03.532495Z","iopub.status.idle":"2023-03-22T18:19:17.744648Z","shell.execute_reply.started":"2023-03-22T18:16:03.532441Z","shell.execute_reply":"2023-03-22T18:19:17.743409Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"****You can use hyperparameter tuning on LR to see if accuracy has any change****","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV\nfrom sklearn.linear_model import LogisticRegression\n\n# define the parameter grid to search over\nparam_grid = {'penalty': ['l1', 'l2'],\n              'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000],\n              'max_iter': [100, 500, 1000, 5000]}\n\n# create a logistic regression object\nlr = LogisticRegression()\n\n# create a grid search object\ngrid_search = GridSearchCV(lr, param_grid, cv=5, scoring='accuracy')\n\n# fit the grid search to the data\ngrid_search.fit(X_train, y_train)\n\n# print the best hyperparameters\nprint(\"Best hyperparameters: \", grid_search.best_params_)\n\n# print the accuracy score for the best hyperparameters\nbest_lr = grid_search.best_estimator_\nbest_lr.fit(X_train, y_train)\ny_pred = best_lr.predict(X_valid)\naccuracy = accuracy_score(y_valid, y_pred)\nprint(\"Accuracy:\", accuracy)\n","metadata":{},"execution_count":null,"outputs":[]}]}